@inproceedings{Perez2021,
abstract = {In content-based image retrieval (CBIR), a database of images is ordered based on the similarity to a query image. Similarity criterion is usually determined with respect to a shared category e.g. whether the database images contain an object of the same type as depicted in the query. Depending on the situation, multiple similarity criteria can be relevant such as the type of object, its color, or the depicted background. Ideally, a dataset labeled with all possible criteria information is available for training a model for computing the similarity. Typically, this is not the case. In this paper, we explore the use of disentangled representations for CBIR with respect to multiple criteria. To alleviate the need for labels, the models used to create the representations are learned via weak supervision by using data organized into groups with shared information. We show that such models can attain better retrieval performances compared to unsupervised baselines.},
author = {{P{\'{e}}rez Rey}, Luis A. and Holenderski, Mike and Jarnikov, Dmitri},
booktitle = {NeurIPS 2021 Deep Generative Models and Downstream Applications Workshop},
file = {:C$\backslash$:/Users/s161416/Downloads/content{\_}based{\_}image{\_}retrieval{\_}.pdf:pdf},
title = {{Content-Based Image Retrieval from Weakly-Supervised Disentangled Representations}},
year = {2021},
url ={https://openreview.net/forum?id=ziB79mBgI-d}
}
@inproceedings{PerezRey2022a,
abstract = {We introduce a method for learning representations that are equivariant with respect to general group actions over data. Differently from existing equivariant representation learners, our method is suitable for actions that are not free i.e., that stabilize data via nontrivial symmetries. Our method is grounded in the orbit-stabilizer theorem from group theory, which guarantees that an ideal learner infers an isomorphic representation. Finally, we provide an empirical investigation on image datasets with rotational symmetries and show that taking stabilizers into account improves the quality of the representations.},
author = {{Perez Rey}, Luis Armando and Marchetti, Giovanni Luca and Kragic, Danica and Jarnikov, Dmitri and Holenderski, Mike},
booktitle = {NeurIPS 2022 Workshop on Symmetry and Geometry in Neural Representations},
keywords = {group theory,representation learning,symmetries},
url={https://openreview.net/forum?id=2w8j23ZUWC4},
title = {{Equivariant Representations for Non-Free Group Actions}},
year = {2022}
}
@inproceedings{Rey2020,
abstract = {The definition of Linear Symmetry-Based Disentanglement (LSBD) proposed by (Higgins et al., 2018) outlines the properties that should characterize a disentangled representation that captures the symmetries of data. However, it is not clear how to measure the degree to which a data representation fulfills these properties. We propose a metric for the evaluation of the level of LSBD that a data representation achieves. We provide a practical method to evaluate this metric and use it to evaluate the disentanglement of the data representations obtained for three datasets with underlying {\$}SO(2){\$} symmetries.},
archivePrefix = {arXiv},
arxivId = {2011.13306},
author = {{P{\'{e}}rez Rey}*, Luis A. and Tonnaer*, Loek and Menkovski, Vlado and Holenderski, Mike and Portegies, Jacobus W.},
booktitle = {NeurIPS 2020 Workshop on Differential Geometry meets Deep Learning},
eprint = {2011.13306},
title = {{A Metric for Linear Symmetry-Based Disentanglement}},
url = {http://arxiv.org/abs/2011.13306},
year = {2020}
}
@article{Tonnaer2020a,
abstract = {The definition of Linear Symmetry-Based Disentanglement (LSBD) formalizes the notion of linearly disentangled representations, but there is currently no metric to quantify LSBD. Such a metric is crucial to evaluate LSBD methods and to compare to previous understandings of disentanglement. We propose {\$}\backslashmathcal{\{}D{\}}{\_}\backslashmathrm{\{}LSBD{\}}{\$}, a mathematically sound metric to quantify LSBD, and provide a practical implementation for {\$}\backslashmathrm{\{}SO{\}}(2){\$} groups. Furthermore, from this metric we derive LSBD-VAE, a semi-supervised method to learn LSBD representations. We demonstrate the utility of our metric by showing that (1) common VAE-based disentanglement methods don't learn LSBD representations, (2) LSBD-VAE as well as other recent methods can learn LSBD representations, needing only limited supervision on transformations, and (3) various desirable properties expressed by existing disentanglement metrics are also achieved by LSBD representations.},
journal={International Conference on Machine Learning},
author = {Tonnaer*, Loek and P{\'{e}}rez Rey*, Luis A. and Menkovski, Vlado and Holenderski, Mike and Portegies, Jacobus W.},
eprint = {2011.06070},
title = {{Quantifying and Learning Linear Symmetry-Based Disentanglement}},
url = {https://proceedings.mlr.press/v162/tonnaer22a.html},
year = {2022}
}
@article{Basiuk2015,
abstract = {We demonstrate the possibility of fast and efficient solvent-free functionalization of buckypaper (BP) mats prefabricated from oxidized multiwalled carbon nanotubes (MWCNTs-ox), by using three representative amines of different structure: one monofunctional aliphatic amine, octadecylamine (ODA), one monofunctional aromatic amine, 1-aminopyrene (AP), and one aromatic diamine, 1,5-diaminonaphthalene (DAN). The functionalization procedure, which relies on the formation of amide bonds with carboxylic groups of MWCNTs-ox, is performed at 150-180 Â°C under reduced pressure and takes about 4 h including auxiliary degassing. The amine-treated BP samples (BP-ODA, BP-AP and BP-DAN, respectively) were characterized by means of a variety of analytical techniques such as Fourier-transform infrared and Raman spectroscopy, thermogravimetric and differential thermal analysis, scanning and transmission electron microscopy, scanning helium ion microscopy, and atomic force microscopy. The highest amine content was found for BP-ODA, and the lowest one was observed for BP-DAN, with a possible contribution of non-covalently bonded amine molecules in all three cases. Despite of some differences in spectral and morphological characteristics for amine-functionalized BP samples, they have in common a dramatically increased stability in water as compared to pristine BP and, on the other hand, a relatively invariable electrical conductivity.},
author = {Basiuk, Elena V. and Ram{\'{i}}rez-Calera, Itzel J. and Meza-Laguna, Victor and Abarca-Morales, Edgar and P{\'{e}}rez-Rey, Luis A. and Re, Marilena and Prete, Paola and Lovergine, Nico and {\'{A}}lvarez-Zauco, Edgar and Basiuk, Vladimir A.},
doi = {10.1016/j.apsusc.2015.09.252},
file = {:C$\backslash$:/Users/s161416/OneDrive - TU Eindhoven/Reading/Articles/Our Papers/Solvent-Free Functionalization of Carbon Nanotube Buckypaper with Amines.pdf:pdf},
issn = {01694332},
journal = {Applied Surface Science},
keywords = {Amines,Buckypaper,Functionalization,Gas phase,Multiwalled carbon nanotubes,Solvent-free},
pages = {1355--1368},
publisher = {Elsevier B.V.},
title = {{Solvent-Free Functionalization of Carbon Nanotube Buckypaper with Amines}},
url = {http://dx.doi.org/10.1016/j.apsusc.2015.09.252},
volume = {357},
year = {2015}
}
@mastersthesis{Rey2018,
author = {{Perez Rey}, Luis A.},
file = {:C$\backslash$:/Users/s161416/Documents/Personal Documents/Papers/Final{\_}Version{\_}Luis{\_}IAM{\_}309.pdf:pdf},
school = {Eindhoven University of Technology},
title = {{Latent Variable Separation with Variational Autoencoders}},
year = {2018}, 
url={https://research.tue.nl/en/studentTheses/latent-variable-separation-with-variational-autoencoders}
}
@article{Yuan2020,
abstract = {3D scene shape retrieval is a brand new but important research direction in content-based 3D shape retrieval. To promote this research area, two Shape Retrieval Contest (SHREC) tracks on 2D scene sketch-based and image-based 3D scene model retrieval have been organized by us in 2018 and 2019, respectively. In 2018, we built the first benchmark for each track which contains 2D and 3D scene data for ten (10) categories, while they share the same 3D scene target dataset. Four and five distinct 3D scene shape retrieval methods have competed with each other in these two contests, respectively. In 2019, to measure and compare the scalability performance of the participating and other promising Query-by-Sketch or Query-by-Image 3D scene shape retrieval methods, we built a much larger extended benchmark for each type of retrieval which has thirty (30) classes and organized two extended tracks. Again, two and three different 3D scene shape retrieval methods have contended in these two tracks, separately. To solicit state-of-the-art approaches, we perform a comprehensive comparison of all the above methods and an additional new retrieval methods by evaluating them on the two benchmarks. The benchmarks, evaluation results and tools are publicly available at our track websites (Yuan et al., 2019 [1]; Abdul-Rashid et al., 2019 [2]; Yuan et al., 2019 [3]; Abdul-Rashid et al., 2019 [4]), while code for the evaluated methods are also available: http://github.com/3DSceneRetrieval.},
author = {Yuan, Juefei and Abdul-Rashid, Hameed and Li, Bo and Lu, Yijuan and Schreck, Tobias and Bai, Song and Bai, Xiang and Bui, Ngoc Minh and Do, Minh N. and Do, Trong Le and Duong, Anh Duc and He, Kai and He, Xinwei and Holenderski, Mike and Jarnikov, Dmitri and Le, Tu Khiem and Li, Wenhui and Liu, Anan and Liu, Xiaolong and Menkovski, Vlado and Nguyen, Khac Tuan and Nguyen, Thanh An and Nguyen, Vinh Tiep and Nie, Weizhi and Ninh, Van Tu and Rey, Perez and Su, Yuting and Ton-That, Vinh and Tran, Minh Triet and Wang, Tianyang and Xiang, Shu and Zhe, Shandian and Zhou, Heyu and Zhou, Yang and Zhou, Zhichao},
doi = {10.1016/j.cviu.2020.103070},
file = {:C$\backslash$:/Users/s161416/Documents/Personal Documents/Papers/A Comparison of Methods for 3D Scene Shape Retrieval.pdf:pdf},
issn = {1090235X},
journal = {Computer Vision and Image Understanding},
keywords = {3D scenes,3D shape retrieval,Performance evaluation,Query-by-Image,Query-by-Sketch,SHREC,Scene benchmark,Scene semantics,Scene understanding},
number = {November 2019},
title = {{A Comparison of Methods for 3D Scene Shape Retrieval}},
volume = {201},
year = {2020}
}
@article{Sipiran2021,
abstract = {This paper presents the methods and results of the SHREC'21 track on a dataset of cultural heritage (CH) objects. We present a dataset of 938 scanned models that have varied geometry and artistic styles. For the competition, we propose two challenges: the retrieval-by-shape challenge and the retrieval-by-culture challenge. The former aims at evaluating the ability of retrieval methods to discriminate cultural heritage objects by overall shape. The latter focuses on assessing the effectiveness of retrieving objects from the same culture. Both challenges constitute a suitable scenario to evaluate modern shape retrieval methods in a CH domain. Ten groups participated in the challenges: thirty runs were submitted for the retrieval-by-shape task, and twenty-six runs were submitted for the retrieval-by-culture task. The results show a predominance of learning methods on image-based multi-view representations to characterize 3D objects. Nevertheless, the problem presented in our challenges is far from being solved. We also identify the potential paths for further improvements and give insights into the future directions of research.},
author = {Sipiran, Ivan and Lazo, Patrick and Lopez, Cristian and Jimenez, Milagritos and Bagewadi, Nihar and Bustos, Benjamin and Dao, Hieu and Gangisetty, Shankar and Hanik, Martin and Ho-Thi, Ngoc Phuong and Holenderski, Mike and Jarnikov, Dmitri and Labrada, Arniel and Lengauer, Stefan and Licandro, Roxane and Nguyen, Dinh Huan and Nguyen-Ho, Thang Long and {Perez Rey}, Luis A. and Pham, Bang Dang and Pham, Minh Khoi and Preiner, Reinhold and Schreck, Tobias and Trinh, Quoc Huy and Tonnaer, Loek and von Tycowicz, Christoph and Vu-Le, The Anh},
doi = {10.1016/j.cag.2021.07.010},
file = {:C$\backslash$:/Users/s161416/Documents/Personal Documents/Papers/SHREC2021.pdf:pdf},
issn = {00978493},
journal = {Computers and Graphics},
keywords = {3D model retrieval,Benchmarking,Cultural heritage},
pages = {1--20},
publisher = {Elsevier Ltd},
title = {{SHREC 2021: Retrieval of Cultural Heritage Objects}},
url = {https://doi.org/10.1016/j.cag.2021.07.010},
volume = {100},
year = {2021}
}
@inproceedings{Rey2019,
abstract = {To what extent can Variational Autoencoders (VAEs) identify semantically meaningful latent variables? Can they at least capture the correct topology if ground-truth latent variables are known? To investigate these questions, we introduce the Diffusion VAE, which allows for arbitrary (closed) manifolds in latent space. A Diffusion VAE uses transition kernels of Brownian motion on the manifold. In particular, it uses properties of the Brownian motion to implement the reparametrization trick and fast approximations to the KL divergence. We show that the Diffusion Variational Autoencoder is indeed capable of capturing topological properties.},
author = {{P{\'{e}}rez Rey}, Luis A. and Menkovski, Vlado and Portegies, Jacobus W.},
file = {:C$\backslash$:/Users/s161416/Documents/Personal Documents/Papers/Can VAEs capture topological properties.pdf:pdf},
number = {Workshop on Bayesian Deep Learning (NeurIPS 2019)},
title = {{Can VAEs Capture Topological Properties?}},
year = {2019},
url={http://bayesiandeeplearning.org/2019/papers/69.pdf}
}
@article{Tonnaer2020,
abstract = {Learning low-dimensional representations that disentangle the underlying factors of variation in data has been posited as an important step towards interpretable machine learning with good generalization. To address the fact that there is no consensus on what disentanglement entails, Higgins et al. (2018) propose a formal definition for Linear Symmetry-Based Disentanglement, or LSBD, arguing that underlying real-world transformations give exploitable structure to data. Although several works focus on learning LSBD representations, such methods require supervision on the underlying transformations for the entire dataset, and cannot deal with unlabeled data. Moreover, none of these works provide a metric to quantify LSBD. We propose a metric to quantify LSBD representations that is easy to compute under certain well-defined assumptions. Furthermore, we present a method that can leverage unlabeled data, such that LSBD representations can be learned with limited supervision on transformations. Using our LSBD metric, our results show that limited supervision is indeed sufficient to learn LSBD representations.},
archivePrefix = {arXiv},
arxivId = {2011.06070},
author = {Tonnaer, Loek and Rey, Luis A. P{\'{e}}rez and Menkovski, Vlado and Holenderski, Mike and Portegies, Jacobus W.},
eprint = {2011.06070},
file = {:C$\backslash$:/Users/s161416/OneDrive - TU Eindhoven/Reading/Articles/Disentanglement/Quantifying and Learning Disentangled Represewntations with Limited Supervision.pdf:pdf},
pages = {1--15},
title = {{Quantifying and Learning Disentangled Representations with Limited Supervision}},
url = {http://arxiv.org/abs/2011.06070},
year = {2020}
}
@article{Alzate-Carvajal2018,
abstract = {Direct functionalization of prefabricated free-standing graphene oxide paper (GOP) is the only approach suitable for systematic tuning of its mechanical, thermal and electronic characteristics. However, the traditional liquid-phase functionalization can compromise physical integrity of the paper-like material up to its total disintegration. In the present paper, we attempted to apply an alternative, solvent-free strategy for facile and nondestructive functionalization of GOP with 1-octadecylamine (ODA) and 1,12-diaminododecane (DAD) as representatives of aliphatic amines, and with 1-aminopyrene (AP) and 1,5-diaminonaphthalene (DAN) as examples of aromatic amines. The functionalization can be carried out under moderate heating at 150-180 Â°C for 2 h in vacuum, and proceeds through both amidation and epoxy ring opening reactions. Comparative characterization of pristine and amine-modified GOP samples was carried out by means of Fourier-transform infrared, Raman, and X-ray photoelectron spectroscopy, thermogravimetric and differential thermal analysis, scanning electron and atomic force microscopy. In addition, we compared stability in water, wettability, electrical conductivity and elastic (Young's) modulus of GOP samples before and after functionalization. The highest content of amine species was obtained in the case of GOP-ODA, followed by GOP-DAD, GOP-AP and GOP-DAN. The functionalization increased mechanical and thermal stability, as well as the electrical conductivity of GOP. The magnitude of each effect depends on the structure of amine employed, which allows for tuning a given GOP characteristic. Morphological characterization showed that, compared to pristine graphene oxide paper, amine-modified mats become relatively ordered layered structures, in which individual GO sheets are organized in a near-parallel fashion.},
author = {Alzate-Carvajal, Natalia and Acevedo-Guzm{\'{a}}n, Diego A. and Meza-Laguna, Victor and Far{\'{i}}as, Mario H. and P{\'{e}}rez-Rey, Luis A. and Abarca-Morales, Edgar and Garc{\'{i}}a-Ram{\'{i}}rez, Victor A. and Basiuk, Vladimir A. and Basiuk, Elena V.},
doi = {10.1039/c8ra00986d},
file = {:C$\backslash$:/Users/s161416/OneDrive - TU Eindhoven/Reading/Articles/Our Papers/One-Step Nondestructive Functionalization of Graphene Oxide Paper with Amines.pdf:pdf},
issn = {20462069},
journal = {RSC Advances},
number = {28},
pages = {15253--15265},
title = {{One-Step Nondestructive Functionalization of Graphene Oxide Paper with Amines}},
volume = {8},
year = {2018}
}
@article{PerezRey2020,
abstract = {A standard Variational Autoencoder, with a Euclidean latent space, is structurally incapable of capturing topological properties of certain datasets. To remove topological obstructions, we introduce Diffusion Variational Autoencoders (?VAE) with arbitrary (closed) manifolds as a latent space. A Diffusion Variational Autoencoder uses transition kernels of Brownian motion on the manifold. In particular, it uses properties of the Brownian motion to implement the reparametrization trick and fast approximations to the KL divergence. We show that the ?VAE is indeed capable of capturing topological properties for datasets with a known underlying latent structure derived from generative processes such as rotations and translations.},
author = {{Perez Rey}, Luis A. and Menkovski, Vlado and Portegies, Jim},
doi = {10.24963/ijcai.2020/375},
eprint = {1901.08991},
isbn = {9780999241165},
issn = {10450823},
journal = {International Joint Conference on Artificial Intelligence},
keywords = {Machine Learning: Bayesian Optimization,Machine Learning: Deep Generative Models,Machine Learning: Dimensionality Reduction and Man},
pages = {2704--2710},
title = {{Diffusion Variational Autoencoders}},
year = {2020}
}
